{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T06:33:37.123827Z",
     "start_time": "2020-02-25T06:33:37.116017Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import  torch.nn.functional as F\n",
    "\n",
    "import Functions as d2l\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_ROOT = \"./Datasets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T06:33:37.771897Z",
     "start_time": "2020-02-25T06:33:37.758096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5.,  8., 11., 14., 17.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##首先实现一维互相关运算\n",
    "def corr1d(x, k):\n",
    "    w = k.shape[0]\n",
    "    y = torch.zeros((x.shape[0] - w + 1))\n",
    "    for i in range(y.shape[0]):\n",
    "        y[i] = (x[i: i + w] * k).sum()\n",
    "    return y\n",
    "\n",
    "\n",
    "x = torch.tensor([0,1,2,3,4,5,6])\n",
    "k = torch.tensor([1,2])\n",
    "corr1d(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T06:33:38.421496Z",
     "start_time": "2020-02-25T06:33:38.402384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  8., 14., 20., 26., 32.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 多通道互相关\n",
    "def corr1d_multi_in(x,k):\n",
    "    return torch.stack([corr1d(x,k) for x,k in zip(x,k)]).sum(dim=0)\n",
    "x = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "k = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(x, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时序最大池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T06:34:49.526814Z",
     "start_time": "2020-02-25T06:34:49.520398Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        # x.shape: (batch_size, channel, seq_len)\n",
    "        # return (batch_size, channel, 1)\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:05:20.488630Z",
     "start_time": "2020-02-25T07:02:34.276202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:39<00:00, 319.53it/s]\n",
      "100%|██████████| 12500/12500 [00:39<00:00, 319.21it/s]\n",
      "100%|██████████| 12500/12500 [00:39<00:00, 319.37it/s]\n",
      "100%|██████████| 12500/12500 [00:39<00:00, 319.64it/s]\n"
     ]
    }
   ],
   "source": [
    "###读取数据\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import collections\n",
    "\n",
    "def read_imdb(folder='train', data_root = './Datasets/aclImdb'):\n",
    "    data = []\n",
    "    for label in ['pos','neg']:\n",
    "        folder_name = os.path.join(data_root, folder, label)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n','').lower()\n",
    "                data.append([review, 1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "## 基于空格进行分词\n",
    "def get_tokenized_imdb(data):\n",
    "    # data: list of [string, label]\n",
    "    def tokenizer(text):\n",
    "        return [token.lower() for token in text.split(' ')]\n",
    "    return [tokenizer(review) for review,_ in data]\n",
    "\n",
    "\n",
    "### 基于分词结果创造词典\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return Vocab.Vocab(counter, min_freq=5)\n",
    "\n",
    "\n",
    "def preprocess_imdb(data, vocab):\n",
    "    max_len = 500  # 将每条评论通过截断或者补0，使得长度变成500\n",
    "    \n",
    "    def pad(x):\n",
    "        return x[:max_len] if len(x) > max_len else x + [0] * (max_len - len(x)) \n",
    "    \n",
    "    tokenized_data = get_tokenized_imdb(data)  ## 基于空格进行分词\n",
    "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels = torch.tensor([score for _, score in data])\n",
    "    return features, labels\n",
    "\n",
    "batch_size = 128\n",
    "train_data = read_imdb('train')\n",
    "test_data = read_imdb('test')\n",
    "vocab = get_vocab_imdb(train_data)\n",
    "\n",
    "train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\n",
    "test_set = Data.TensorDataset(*preprocess_imdb(test_data, vocab))\n",
    "train_iter = Data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "test_iter = Data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:50:14.179963Z",
     "start_time": "2020-02-25T07:50:14.166356Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, kernel_sizes, channels):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        self.constant_embedding = nn.Embedding(len(vocab), embed_size) # 不参与训练\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.decoder = nn.Linear(sum(channels),2)\n",
    "        self.pool = GlobalMaxPool1d()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels = 2*embed_size,\n",
    "                                        out_channels = c,\n",
    "                                        kernel_size = k))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # 将两个形状是(批量大小, 词数, 词向量维度)的嵌入层的输出按词向量连结\n",
    "        embeddings = torch.cat((self.embedding(inputs), self.constant_embedding(inputs)), \n",
    "                                                       dim=2) # (batch, seq_len, 2*embed_size)\n",
    "        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维(即词向量那一维)，变换到前一维\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的\n",
    "        # Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\n",
    "        encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        # 应用丢弃法后使用全连接层得到输出\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:54:03.035779Z",
     "start_time": "2020-02-25T07:54:02.935723Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:54:05.645739Z",
     "start_time": "2020-02-25T07:54:03.586886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21202 oov words.\n",
      "There are 21202 oov words.\n"
     ]
    }
   ],
   "source": [
    "glove_vocab = Vocab.GloVe(name='6B', dim=100,\n",
    "                        cache=os.path.join(DATA_ROOT, \"glove\"))\n",
    "net.embedding.weight.data.copy_(\n",
    "    d2l.load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.data.copy_(\n",
    "    d2l.load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.constant_embedding.weight.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:58:46.510284Z",
     "start_time": "2020-02-25T07:54:05.647273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4688, train acc 0.770, test acc 0.847, time 14.0 sec\n",
      "epoch 2, loss 0.1522, train acc 0.871, test acc 0.869, time 14.0 sec\n",
      "epoch 3, loss 0.0673, train acc 0.922, test acc 0.881, time 14.0 sec\n",
      "epoch 4, loss 0.0285, train acc 0.961, test acc 0.869, time 14.0 sec\n",
      "epoch 5, loss 0.0109, train acc 0.984, test acc 0.882, time 14.0 sec\n",
      "epoch 6, loss 0.0036, train acc 0.996, test acc 0.880, time 14.0 sec\n",
      "epoch 7, loss 0.0016, train acc 0.999, test acc 0.878, time 14.0 sec\n",
      "epoch 8, loss 0.0009, train acc 0.999, test acc 0.875, time 14.1 sec\n",
      "epoch 9, loss 0.0005, train acc 1.000, test acc 0.878, time 14.0 sec\n",
      "epoch 10, loss 0.0003, train acc 1.000, test acc 0.877, time 14.0 sec\n",
      "epoch 11, loss 0.0002, train acc 1.000, test acc 0.872, time 14.1 sec\n",
      "epoch 12, loss 0.0001, train acc 1.000, test acc 0.876, time 14.0 sec\n",
      "epoch 13, loss 0.0001, train acc 1.000, test acc 0.874, time 14.0 sec\n",
      "epoch 14, loss 0.0001, train acc 1.000, test acc 0.874, time 14.0 sec\n",
      "epoch 15, loss 0.0001, train acc 1.000, test acc 0.875, time 14.0 sec\n",
      "epoch 16, loss 0.0000, train acc 1.000, test acc 0.872, time 14.0 sec\n",
      "epoch 17, loss 0.0000, train acc 1.000, test acc 0.871, time 14.1 sec\n",
      "epoch 18, loss 0.0000, train acc 1.000, test acc 0.860, time 14.1 sec\n",
      "epoch 19, loss 0.0000, train acc 1.000, test acc 0.871, time 14.1 sec\n",
      "epoch 20, loss 0.0000, train acc 1.000, test acc 0.872, time 14.1 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 20\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "d2l.train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wangkai3.6",
   "language": "python",
   "name": "wangkai3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
