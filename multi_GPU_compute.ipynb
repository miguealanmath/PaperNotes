{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T06:38:19.986429Z",
     "start_time": "2020-02-20T06:38:19.971043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=1, bias=True)\n",
      "---------------------\n",
      "DataParallel(\n",
      "  (module): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Linear(10,1)\n",
    "print(net)\n",
    "print('---------------------')\n",
    "net = torch.nn.DataParallel(net, device_ids=[0,3])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:08:09.105947Z",
     "start_time": "2020-02-19T10:08:09.095268Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.module.state_dict(), './networks/multiGPU.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:08:13.518899Z",
     "start_time": "2020-02-19T10:08:13.507715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net = torch.nn.Linear(10,1)\n",
    "new_net.load_state_dict(torch.load(\"./networks/multiGPU.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:08:18.212943Z",
     "start_time": "2020-02-19T10:08:18.195121Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:09:03.546757Z",
     "start_time": "2020-02-19T10:09:03.455835Z"
    }
   },
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:10:47.189406Z",
     "start_time": "2020-02-19T10:10:47.133739Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "class GlobalAvgPool2d(torch.nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   GlobalAvgPool2d())\n",
    "\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "net = torch.nn.DataParallel(net, device_ids=[0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:10:52.596142Z",
     "start_time": "2020-02-19T10:10:52.567965Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
    "    import torchvision\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, nn.Module):\n",
    "        ##如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x ,y in data_iter:\n",
    "            if isinstance(net, nn.Module):\n",
    "                net.eval()\n",
    "                acc_sum += (net(x.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else:##自定义模型\n",
    "                if ('is_training' in net.__code__.co_varnames):\n",
    "                    ##将is_training设置为false\n",
    "                    acc_sum += (net(x, is_training = False).argmax(dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(x).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "                \n",
    "    \n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, epochs):\n",
    "    net = net.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_ls_sum, train_acc_sum = 0, 0\n",
    "        n = 0\n",
    "        batch_count = 0\n",
    "        start = time.time()\n",
    "        for x, y in train_iter:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(x)\n",
    "            ls = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            ls.backward()\n",
    "            optimizer.step()\n",
    "            train_ls_sum += ls.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        \n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_ls_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T10:46:26.851441Z",
     "start_time": "2020-02-19T10:35:45.569087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.6004, train acc 0.775, test acc 0.781, time 21.2 sec\n",
      "epoch 2, loss 0.4678, train acc 0.828, test acc 0.826, time 21.1 sec\n",
      "epoch 3, loss 0.4106, train acc 0.847, test acc 0.840, time 21.2 sec\n",
      "epoch 4, loss 0.3586, train acc 0.865, test acc 0.862, time 21.2 sec\n",
      "epoch 5, loss 0.3303, train acc 0.876, test acc 0.865, time 21.3 sec\n",
      "epoch 6, loss 0.3069, train acc 0.884, test acc 0.869, time 21.3 sec\n",
      "epoch 7, loss 0.2847, train acc 0.894, test acc 0.878, time 21.3 sec\n",
      "epoch 8, loss 0.2734, train acc 0.898, test acc 0.874, time 21.4 sec\n",
      "epoch 9, loss 0.2615, train acc 0.900, test acc 0.881, time 21.5 sec\n",
      "epoch 10, loss 0.2512, train acc 0.906, test acc 0.894, time 21.3 sec\n",
      "epoch 11, loss 0.2358, train acc 0.912, test acc 0.890, time 21.3 sec\n",
      "epoch 12, loss 0.2290, train acc 0.914, test acc 0.886, time 21.2 sec\n",
      "epoch 13, loss 0.2207, train acc 0.917, test acc 0.903, time 21.3 sec\n",
      "epoch 14, loss 0.2108, train acc 0.921, test acc 0.894, time 21.5 sec\n",
      "epoch 15, loss 0.2045, train acc 0.923, test acc 0.903, time 21.6 sec\n",
      "epoch 16, loss 0.2006, train acc 0.925, test acc 0.901, time 21.4 sec\n",
      "epoch 17, loss 0.1891, train acc 0.930, test acc 0.906, time 21.2 sec\n",
      "epoch 18, loss 0.1805, train acc 0.932, test acc 0.905, time 21.5 sec\n",
      "epoch 19, loss 0.1736, train acc 0.935, test acc 0.903, time 21.3 sec\n",
      "epoch 20, loss 0.1629, train acc 0.938, test acc 0.907, time 21.5 sec\n",
      "epoch 21, loss 0.1662, train acc 0.938, test acc 0.907, time 21.5 sec\n",
      "epoch 22, loss 0.1491, train acc 0.943, test acc 0.909, time 21.5 sec\n",
      "epoch 23, loss 0.1488, train acc 0.943, test acc 0.909, time 21.5 sec\n",
      "epoch 24, loss 0.1460, train acc 0.945, test acc 0.905, time 21.3 sec\n",
      "epoch 25, loss 0.1402, train acc 0.947, test acc 0.901, time 21.6 sec\n",
      "epoch 26, loss 0.1386, train acc 0.948, test acc 0.901, time 21.2 sec\n",
      "epoch 27, loss 0.1246, train acc 0.952, test acc 0.909, time 21.5 sec\n",
      "epoch 28, loss 0.1236, train acc 0.952, test acc 0.902, time 21.4 sec\n",
      "epoch 29, loss 0.1153, train acc 0.956, test acc 0.907, time 21.3 sec\n",
      "epoch 30, loss 0.1138, train acc 0.958, test acc 0.906, time 21.6 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 30\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML3.6",
   "language": "python",
   "name": "ml3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
