{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**本文是一篇关于如何用Pytorch保存和加载模型的指南。**\n",
    "\n",
    "本文主要涉及到3个函数：\n",
    "1. `torch.save`: 使用Python的pickle实用程序将对象进行序列化，然后将序列化的对象保存到disk，可以保存各种对象,包括模型、张量和字典等。\n",
    "2. `torch.load`: 使用pickle unpickle工具将pickle的对象文件反序列化为内存。\n",
    "3. `torch.nn.Module.load_state_dict`: 用反序列化的*state_dict*来加载模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读写tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:29:53.476273Z",
     "start_time": "2020-02-13T05:29:53.463203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.,4.])\n",
    "torch.save(x, 'x.pt')\n",
    "x1 = torch.load('x.pt')\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:29:23.986447Z",
     "start_time": "2020-02-13T05:29:23.969341Z"
    }
   },
   "source": [
    "### 张量列表和张量词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:34:11.543104Z",
     "start_time": "2020-02-13T05:34:11.521897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3., 4.]), tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])]\n",
      "{'x': tensor([3., 4.]), 'y': tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])}\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones((4,2))\n",
    "torch.save([x,y],'xy.pt')\n",
    "torch.save({'x':x, 'y':y}, 'xy_dict.pt')\n",
    "xy = torch.load('xy.pt')\n",
    "xy_dict = torch.load('xy_dict.pt')\n",
    "print(xy)\n",
    "print(xy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:37:33.152509Z",
     "start_time": "2020-02-13T05:37:33.148844Z"
    }
   },
   "source": [
    "### *state_dict*\n",
    "state_dict是一个从每一个层的名称映射到这个层的参数Tesnor的字典对象。\n",
    "\n",
    "注意，只有具有可学习参数的层(卷积层、线性层等)和注册缓存(batchnorm's running_mean)才有state_dict中的条目。优化器(`torch.optim`)也有一个state_dict，其中包含关于优化器状态以及所使用的超参数的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:49:43.676396Z",
     "start_time": "2020-02-13T05:49:43.658538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden.weight', tensor([[ 0.1493, -0.1645,  0.5165],\n",
      "        [-0.0773,  0.3487,  0.4961]])), ('hidden.bias', tensor([-0.4560, -0.5111])), ('output.weight', tensor([[0.3356, 0.4229]])), ('output.bias', tensor([-0.6374]))])\n",
      "\n",
      " tensor([[0.3356, 0.4229]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'momentum': 0.9,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [139788808398168,\n",
       "    139788808397952,\n",
       "    139788808397736,\n",
       "    139788808398096]}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(3, 2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)\n",
    "\n",
    "net = MLP()\n",
    "print(net.state_dict())\n",
    "print('\\n',net.state_dict()['output.weight'])\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:50:44.368292Z",
     "start_time": "2020-02-13T05:50:44.365263Z"
    }
   },
   "source": [
    "### 保存和加载\n",
    "PyTorch中保存和加载训练模型有两种常见的方法:\n",
    "\n",
    "1. 仅保存和加载模型参数(state_dict)；\n",
    "2. 保存和加载整个模型。\n",
    "\n",
    "#### 保存和加载state_dict(推荐方式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T05:53:38.648532Z",
     "start_time": "2020-02-13T05:53:38.633030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(net.state_dict(), 'net_state_dict.pt')## 后缀名一般写为: .pt或.pth\n",
    "net1 = MLP()\n",
    "net1.load_state_dict(torch.load('net_state_dict.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意:** ``load_state_dict()`` 接受一个词典对象，而不是一个指向对象的路径。因此你需要先使用`torch.load()`来反序列化。比如，你不能直接这么用``model.load_state_dict(PATH)``。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T06:06:35.251076Z",
     "start_time": "2020-02-13T06:06:35.246237Z"
    }
   },
   "source": [
    "#### 保存和读写整个模型\n",
    "这个就相对来说比较简单了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T07:06:38.046731Z",
     "start_time": "2020-02-13T07:06:38.033639Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, 'net.pt')\n",
    "net2 = torch.load('net.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：**以这种方式保存模型将使用Python的pickle模块保存整个模块。 这种方法的缺点是序列化的数据被绑定到特定的类，并且在保存模型时使用了确切的词典结构。 这样做的原因是因为pickle不会保存模型类本身。 而是将其保存到包含这个类的文件的路径，该路径在加载时使用。 因此，在其他项目中使用或重构后，您的代码可能会以各种方式中断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T06:29:06.580145Z",
     "start_time": "2020-02-13T06:29:06.572360Z"
    }
   },
   "source": [
    "#### 保存和加载checkpiont\n",
    "```python\n",
    "## Save\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "## Load\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存用于检查或继续训练的checkpiont时，你必须保存的不只是模型的state_dict。 保存优化器的state_dict也很重要，因为它包含随着模型训练而更新的缓冲区和参数。 你可能要保存的其他项目包括你未设置的时间段，最新记录的训练损失，外部`torch.nn.Embedding`层等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在一个文件中保存多个模型\n",
    "```python\n",
    "#Save\n",
    "torch.save({\n",
    "            'modelA_state_dict': modelA.state_dict(),\n",
    "            'modelB_state_dict': modelB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict(),\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "\n",
    "#Load\n",
    "modelA = TheModelAClass(*args, **kwargs)\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "optimizerA = TheOptimizerAClass(*args, **kwargs)\n",
    "optimizerB = TheOptimizerBClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "```\n",
    "\n",
    "常见的PyTorch约定是使用`.tar`文件扩展名保存这些检查点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T06:27:03.914958Z",
     "start_time": "2020-02-13T06:27:03.909831Z"
    }
   },
   "source": [
    "### 使用来自不同模型的参数进行模型热启动\n",
    "这种方法一般用于迁移学习。利用经过训练的参数，即使只有少数几个可用的参数，也将有助于热启动训练过程，并希望与从头开始训练相比，可以更快地收敛模型。\n",
    "\n",
    "```python\n",
    "torch.save(modelA.state_dict(), PATH)\n",
    "\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "modelB.load_state_dict(torch.load(PATH), strict=False)\n",
    "```\n",
    "无论是从缺少某些键的部分state_dict加载，还是加载比要加载的模型更多的key的state_dict，都可以在load_state_dict()函数中将strict参数设置为False，以忽略不匹配键。\n",
    "\n",
    "如果你想要将一个层的参数加载到另一个层，但是一些keys不匹配，你只需改变你所加载的state_dict中的名称即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T06:49:03.693635Z",
     "start_time": "2020-02-13T06:49:03.689728Z"
    }
   },
   "source": [
    "## 跨设备保存和加载模型\n",
    "### 在GPU中保存，在CPU中加载\n",
    "```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "```\n",
    "\n",
    "### 在GPU中保存，在GPU中加载\n",
    "\n",
    "```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "### 在CPU中保存，在GPU中加载\n",
    "\n",
    "```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
    "model.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存`torch.nn.DataParallel`的模型\n",
    "```python\n",
    "torch.save(model.module.state_dict(), PATH)\n",
    "\n",
    "# Load to whatever device you want,加载方法使用常规方式即可。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML3.6",
   "language": "python",
   "name": "ml3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
